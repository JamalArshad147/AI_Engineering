{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78e372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c9671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamal Arshad\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to a type of artificial intelligence that is capable of acting autonomously in the world, making decisions and taking actions based on its understanding of its environment and objectives. The concept emphasizes the idea of agency, meaning that the AI system can operate independently, exhibit goal-directed behavior, and adapt to changes in its surroundings.\n",
      "\n",
      "Key characteristics of Agentic AI include:\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems can perform tasks without human intervention, using learned knowledge and strategies to navigate complex situations.\n",
      "\n",
      "2. **Decision-Making**: They are equipped with algorithms that allow them to analyze data, consider various outcomes, and choose actions that align with their goals.\n",
      "\n",
      "3. **Adaptability**: Agentic AI can learn from its experiences, adjust its strategies based on feedback, and improve its performance over time.\n",
      "\n",
      "4. **Goal-Directed Behavior**: These systems are designed with specific objectives in mind, whether it's optimizing a process, improving efficiency, or solving a problem.\n",
      "\n",
      "5. **Interaction**: Agentic AI can engage with humans and other systems, making it capable of collaborating or competing in various contexts.\n",
      "\n",
      "Applications of Agentic AI can be found across various fields, including robotics, autonomous vehicles, healthcare, finance, and many others, where decision-making speed and efficiency are critical.\n",
      "\n",
      "It's important to note that the development of Agentic AI raises ethical and safety considerations, such as ensuring that these systems align with human values, remain transparent, and can be controlled or overridden when necessary.\n"
     ]
    }
   ],
   "source": [
    "# Chat Models\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "output = llm.invoke(\"Explain Agentic AI...\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d8821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In winter winds that whisper low,  \n",
      "Code compiles beneath the glow,  \n",
      "A silver moon in quiet skies,  \n",
      "While coffee warms, my thoughts arise.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content = \"you are a poet\"),\n",
    "    HumanMessage(content='Write four lines on winter winds, coding, moon and coffee')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0050fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching LLM Responses\n",
    "\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.cache import InMemoryCache\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = \"Write 4 lines on Nature and Winter winds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86193a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Beneath the barren trees, the winter winds sigh,  \\nWhispers of frost weave through the chilly sky.  \\nNature slumbers softly, cloaked in purest white,  \\nA tranquil world awaits the warmth of spring's light.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 16, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ9SLKifPBYGXvrnJbXNL1QUE1b0m', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5fb115a6-03b9-423e-bbef-11faf8121481-0', usage_metadata={'input_tokens': 16, 'output_tokens': 48, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fe4947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Beneath the barren trees, the winter winds sigh,  \\nWhispers of frost weave through the chilly sky.  \\nNature slumbers softly, cloaked in purest white,  \\nA tranquil world awaits the warmth of spring's light.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 16, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ9SLKifPBYGXvrnJbXNL1QUE1b0m', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5fb115a6-03b9-423e-bbef-11faf8121481-0', usage_metadata={'input_tokens': 16, 'output_tokens': 48, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723fb346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In whispers of the night, the code does hum,  \n",
      "A symphony of logic, where ideas come.  \n",
      "Lines of thought entwined like vines so green,  \n",
      "A dance of digits on a glowing screen.  \n",
      "\n",
      "In the labyrinth of syntax, we bravely tread,  \n",
      "Crafting worlds with symbols, where dreams are fed.  \n",
      "A loop spins stories, conditions set the stage,  \n",
      "In every iteration, we turn a new page.  \n",
      "\n",
      "Functions like friends, they gather and greet,  \n",
      "Returning their treasures, making each task sweet.  \n",
      "With every semicolon, a pause to reflect,  \n",
      "In this language of magic, we build and connect.  \n",
      "\n",
      "Errors might whisper, “You’ve strayed from the path,”  \n",
      "But with patience and logic, we harness their wrath.  \n",
      "Debugging our spirits, line by line we find,  \n",
      "The beauty in challenges that sharpen the mind.  \n",
      "\n",
      "From simple “Hello, World!” to visions so grand,  \n",
      "With HTML, CSS, our dreams take a stand.  \n",
      "In Python’s embrace or Java’s strong arms,  \n",
      "We conjure up wonders, seducing with charms.  \n",
      "\n",
      "In the realm of the digital, our minds become free,  \n",
      "A canvas of zeros, a tapestry of three.  \n",
      "So here’s to the coders, the dreamers who dare,  \n",
      "In the depths of their coding, new worlds they share.  "
     ]
    }
   ],
   "source": [
    "# LLM Streaming\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "prompt = \"Write poem on code\"\n",
    "\n",
    "for chunk in llm.stream(prompt):\n",
    "    if chunk is not None:\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a89b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an experienced Virologist. Write a few senteces about the following virus HTLV-1 in English\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human T-cell lymphotropic virus type 1 (HTLV-1) is a retrovirus that primarily infects T-cells, a type of white blood cell crucial for the immune response. It is associated with several diseases, including adult T-cell leukemia/lymphoma (ATLL) and tropical spastic paraparesis/HTLV-1-associated myelopathy (TSP/HAM). Transmission occurs mainly through sexual contact, blood transfusions, and from mother to child via breastfeeding. Despite its association with serious health conditions, many individuals infected with HTLV-1 remain asymptomatic for years, making early detection and monitoring important for managing potential complications. Research continues to explore the virus's mechanisms of pathogenesis and potential therapeutic strategies.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplates\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experienced Virologist. Write a few senteces about the following virus {virus} in {language}'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "prompt = prompt_template.format(virus='HTLV-1', language='English')\n",
    "print(prompt)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5316c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Bye bye!\n"
     ]
    }
   ],
   "source": [
    "# Define role msg\n",
    "# Cache \n",
    "# Streaming\n",
    "# PromptTemplate\n",
    "\n",
    "import time\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "\n",
    "template = '''You are an experienced AI engineer with over 2 decades of experience. Explain {user_prompt} in simple words in 3 lines max and output shouldn't be just one long line'''\n",
    "\n",
    "while True:\n",
    "\n",
    "    user_input = input('User: ').strip().lower()\n",
    "\n",
    "    if user_input.lower() not in ['bye', 'exit', 'stop']:\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template).format(user_prompt = user_input)\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"PROMPT: \", prompt)\n",
    "        print(\"----------------------------\")\n",
    "        # for chunk in llm.stream(prompt):\n",
    "        #     if (chunk is not None ):\n",
    "        #         print(chunk.content, end=\"\")\n",
    "\n",
    "        llm.invoke(prompt)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"\\n\\n[Generation took {elapsed_time:.2f} seconds]\\n\")\n",
    "\n",
    "    else:\n",
    "        print('Saving...')\n",
    "        time.sleep(4)\n",
    "        print(\"Bye bye!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51428c1a",
   "metadata": {},
   "source": [
    "## Chaining in Langchain ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f916bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain, SimpleSequentialChain    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd607aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamal Arshad\\AppData\\Local\\Temp\\ipykernel_22396\\3643328350.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_1 = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "llm_1 = ChatOpenAI(model='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "prompt_template_1 = PromptTemplate.from_template(template='You are an experienced AI Scientist and Python developer, Write a function on {concept} with details and coding examples')\n",
    "\n",
    "chain_1 = LLMChain(\n",
    "    llm = llm_1,\n",
    "    prompt = prompt_template_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237ecde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = ChatOpenAI(model='gpt-4o-mini', temperature=1.5)\n",
    "\n",
    "prompt_template_2 = PromptTemplate.from_template(template='Given the python {function} describe in details.')\n",
    "\n",
    "chain_2 = LLMChain(\n",
    "    llm = llm_2,\n",
    "    prompt = prompt_template_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db6e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure! Let's dive into a fundamental concept in Machine Learning: **linear regression**. Linear regression is a supervised learning algorithm used for predicting a continuous target variable based on one or more predictor variables (features). \n",
      "\n",
      "### What is Linear Regression?\n",
      "\n",
      "Linear regression attempts to model the relationship between two variables by fitting a linear equation to the observed data. The simplest form (simple linear regression) uses one feature to predict the target variable, while multiple linear regression uses multiple features.\n",
      "\n",
      "The linear equation can be represented as:\n",
      "\n",
      "\\[ y = mx + b \\]\n",
      "\n",
      "Where:\n",
      "- \\( y \\) is the predicted value.\n",
      "- \\( m \\) is the slope of the line (coefficient).\n",
      "- \\( x \\) is the feature (input).\n",
      "- \\( b \\) is the y-intercept.\n",
      "\n",
      "### Steps to Implement Linear Regression\n",
      "\n",
      "1. **Import Libraries**: You'll need libraries like `numpy`, `pandas`, and `scikit-learn` for data manipulation and modeling.\n",
      "2. **Load Data**: Use a dataset for training and testing the model.\n",
      "3. **Preprocess Data**: Handle missing values, encode categorical variables, and split the data into training and testing sets.\n",
      "4. **Train the Model**: Fit the linear regression model on the training data.\n",
      "5. **Make Predictions**: Use the model to make predictions on the test set.\n",
      "6. **Evaluate the Model**: Assess the model's performance using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), or R-squared.\n",
      "\n",
      "### Coding Example\n",
      "\n",
      "Here’s a complete example of implementing linear regression using Python and the `scikit-learn` library.\n",
      "\n",
      "```python\n",
      "# Importing necessary libraries\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
      "\n",
      "# Load a sample dataset (e.g., Boston housing dataset)\n",
      "from sklearn.datasets import load_boston\n",
      "boston = load_boston()\n",
      "data = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
      "data['PRICE'] = boston.target\n",
      "\n",
      "# Display the first few rows of the dataset\n",
      "print(data.head())\n",
      "\n",
      "# Define the feature and target variable\n",
      "X = data[['RM']]  # Using 'RM' (average number of rooms) as the feature\n",
      "y = data['PRICE']  # Target variable is 'PRICE'\n",
      "\n",
      "# Split the dataset into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Create a Linear Regression model\n",
      "model = LinearRegression()\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Evaluate the model\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "mae = mean_absolute_error(y_test, y_pred)\n",
      "r2 = r2_score(y_test, y_pred)\n",
      "\n",
      "print(f'Mean Squared Error: {mse}')\n",
      "print(f'Mean Absolute Error: {mae}')\n",
      "print(f'R-squared: {r2}')\n",
      "\n",
      "# Visualize the results\n",
      "plt.scatter(X_test, y_test, color='blue', label='Actual Prices')\n",
      "plt.scatter(X_test, y_pred, color='red', label='Predicted Prices')\n",
      "plt.plot(X_test, y_pred, color='green', linewidth=2, label='Regression Line')\n",
      "plt.title('Linear Regression: Actual vs Predicted Prices')\n",
      "plt.xlabel('Average Number of Rooms (RM)')\n",
      "plt.ylabel('House Price')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "### Explanation of the Code\n",
      "\n",
      "1. **Import Libraries**: We import necessary libraries for data manipulation, visualization, and machine learning.\n",
      "2. **Load Dataset**: We load the Boston housing dataset and convert it into a DataFrame.\n",
      "3. **Define Features and Target**: We select the feature (`RM`) and target variable (`PRICE`).\n",
      "4. **Train-Test Split**: We split the dataset into training (80%) and testing (20%) sets.\n",
      "5. **Model Training**: We create an instance of `LinearRegression` and fit it to the training data.\n",
      "6. **Predictions**: We make predictions on the test set.\n",
      "7. **Model Evaluation**: We calculate and print the Mean Squared Error, Mean Absolute Error, and R-squared values to evaluate the model's performance.\n",
      "8. **Visualization**: We visualize the actual vs. predicted prices using a scatter plot.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "This example provides a basic understanding of how to implement linear regression in Python using `scikit-learn`. You can expand upon this by exploring multiple linear regression, feature engineering, and more advanced evaluation metrics. Linear regression serves as a foundational concept for many more complex machine learning algorithms.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chains = SimpleSequentialChain(chains=[chain_1, chain_2], verbose=True)\n",
    "output = chains.invoke(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbc759",
   "metadata": {},
   "source": [
    "## Langchain Agents ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade langchain-core langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade langchain langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463576fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aedd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# python_repl = PythonREPL()\n",
    "# python_repl.run('print([n for n in range(1,100) if n%13==0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee542f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.agents.agent_toolkits import create_python_agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
